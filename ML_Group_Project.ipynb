{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4cf-jTU2qVn"
      },
      "source": [
        "01. Business Problem and Introduction  \n",
        "02. Data Loading and Initial Exploration  \n",
        "03. Data Cleaning and Preprocessing  \n",
        "04. Feature Engineering  \n",
        "05. Exploratory Data Analysis (EDA)  \n",
        "06. Modeling Strategy and Data Splitting  \n",
        "07. Model Training and Evaluation  \n",
        "08. Interpretation and Business Recommendations  \n",
        "09. Conclusion and Next Steps  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8fvdAwC2tSZ"
      },
      "source": [
        "## Business Context\n",
        "\n",
        "Type II diabetes is a chronic condition affecting over 37 million Americans. In 2017 alone, diabetes-related healthcare costs exceeded $327 billion in the U.S., with a significant portion attributed to hospital readmissions. Unplanned readmissions strain the healthcare system and may indicate gaps in treatment or patient management.\n",
        "\n",
        "### Readmission Classes\n",
        "- **NO**: No readmission (53.9%)\n",
        "- **<30**: Readmitted within 30 days (34.9%)\n",
        "- **>30**: Readmitted after 30 days (11.2%)\n",
        "\n",
        "### Objective\n",
        "Predict patient readmission class using historical medical records. Accurate predictions can:\n",
        "- Reduce avoidable readmissions\n",
        "- Enable targeted care\n",
        "- Save costs and improve patient outcomes\n",
        "\n",
        "### References\n",
        "- CDC (https://www.cdc.gov/diabetes/data/index.html)\n",
        "- Kaggle dataset (https://www.kaggle.com/datasets/brandao/diabetes)\n",
        "- PubMed article (https://pubmed.ncbi.nlm.nih.gov/24804245/)\n",
        "\n",
        "\n",
        "Citation example: CDC, PubMed, Kaggle links from assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUkHtS8L6Bi8"
      },
      "source": [
        "# üìÅ 02. Data Loading and Initial Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WguhpqTYnXNn"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_eGTChKw2wOx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Wh91pvsRnYpz",
        "outputId": "f8bfd02e-b1da-42eb-fd8b-9b868fae1712"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'diabetic_readmission_data.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-afec14840e3a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"diabetic_readmission_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diabetic_readmission_data.csv'"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"diabetic_readmission_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w4OW_pPi6d6s"
      },
      "outputs": [],
      "source": [
        "# Dataset overview\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kxwxFqcG8O6N"
      },
      "outputs": [],
      "source": [
        "# Number of entries\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m4JwRCeInpqE"
      },
      "outputs": [],
      "source": [
        "# Displaying first 10 rows of data - so we can see every feature\n",
        "df.head(10).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DXr0CDMQ8aMn"
      },
      "outputs": [],
      "source": [
        "# Display basic summary statistics for all columns\n",
        "print(\"Summary Statistics:\")\n",
        "print(df.describe(include='all'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EvdzAQwIntjR"
      },
      "outputs": [],
      "source": [
        "# Checking for missing values in dataset\n",
        "# In the dataset missing values are represented as '?' sign\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == object:\n",
        "         print(col,df[col][df[col] == '?'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nBe7KdfBnwkg"
      },
      "outputs": [],
      "source": [
        "# Summarised version\n",
        "\n",
        "# Check for missing values represented by '?'\n",
        "missing_values = df.applymap(lambda x: x == '?').sum()\n",
        "\n",
        "# Print the count of missing values for each column\n",
        "print(missing_values[missing_values > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LTZUwQJuArzz"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of missing values for each column\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "\n",
        "# Filter for columns with missing values\n",
        "missing_percentage_filtered = missing_percentage[missing_percentage > 0]\n",
        "\n",
        "# Convert numerical values to string with a trailing '%' sign and two decimal places\n",
        "missing_percentage_formatted = missing_percentage_filtered.apply(lambda x: f\"{x:.2f}%\")\n",
        "\n",
        "# Print a title\n",
        "print(\"===== Percentage of Missing Values per Column =====\")\n",
        "\n",
        "# Print the formatted percentages\n",
        "missing_percentage_formatted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzwiCmNDKOhn"
      },
      "source": [
        "## Create is_missing column for weight and payer_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SthfYVzB3W-"
      },
      "source": [
        "Since weight and payer_code have >30% of rows missing - we will create is_missing column because it could be a meaningful signal\n",
        "- perhaps patients who did not have a particular measurement recorded are more (or less) likely to be readmitted.\n",
        "- maybe certain hospitals only record weight for high-risk patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WDEYjBRfCUt7"
      },
      "outputs": [],
      "source": [
        "# Duplicate df with is_missing column for weight and payer_code\n",
        "\n",
        "# Create a copy of the DataFrame\n",
        "df_copy = df.copy()\n",
        "\n",
        "# Create 'is_missing_weight' and 'is_missing_payer_code' columns\n",
        "df_copy['is_missing_weight'] = df_copy['weight'] == '?'\n",
        "df_copy['is_missing_payer_code'] = df_copy['payer_code'] == '?'\n",
        "df_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fvgs4uWRn93q"
      },
      "outputs": [],
      "source": [
        "# Gender was coded differently (either Male, Female, or Unknonw/Invalid) so we use a custom count for this one\n",
        "print('gender', df['gender'][df['gender'] == 'Unknown/Invalid'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GHxOaBcW6kNz"
      },
      "outputs": [],
      "source": [
        "# Column data types\n",
        "df.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nvODGR4O-rXE"
      },
      "outputs": [],
      "source": [
        "# Identify numerical (int64) columns\n",
        "\n",
        "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
        "numerical_cols = df.select_dtypes(include=['int64']).columns\n",
        "numerical_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DOhJHFoH-zdQ"
      },
      "outputs": [],
      "source": [
        "# prompt: Identify categorical (object) columns\n",
        "\n",
        "# Identify categorical (object) columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "categorical_cols\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu9FBIxyoWRY"
      },
      "source": [
        "## Initial Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPeKUFKeoYFi"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF0ZomN0obKb"
      },
      "source": [
        "#### Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MVNFeKiwoWty"
      },
      "outputs": [],
      "source": [
        "# Histograms for numeric features to visualize distributions\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols].hist(bins=30, figsize=(15, 10))\n",
        "plt.suptitle(\"Histograms of Numeric Features\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZw69elNocI4"
      },
      "source": [
        "#### Boxplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZuWkG0Aloet_"
      },
      "outputs": [],
      "source": [
        "# Boxplots for each numeric feature to help identify outliers\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.boxplot(x=df[col])\n",
        "    plt.title(f\"Boxplot of {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSs4PQQ2oe8V"
      },
      "source": [
        "#### Bar Charts for Categorical Variables:\n",
        "\n",
        "For features like:\n",
        "- readmission class and\n",
        "- diagnosis codes,\n",
        "\n",
        "**Why?**\n",
        "<br>\n",
        "To observe the frequency distribution and identify any significant imbalances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0QOCryb2pRcG"
      },
      "outputs": [],
      "source": [
        "# Bar chart for diagnosis codes\n",
        "plt.figure(figsize=(12, 6))\n",
        "df['diag_1'].value_counts().nlargest(20).plot(kind='bar') # Plotting top 20 diagnosis codes\n",
        "plt.title('Top 20 diag_1 Code Frequencies')\n",
        "plt.xlabel('Diagnosis Code')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YjmxfnJ-1Rtp"
      },
      "outputs": [],
      "source": [
        "# Bar chart for diag_2\n",
        "plt.figure(figsize=(12, 6))\n",
        "df['diag_2'].value_counts().nlargest(20).plot(kind='bar')\n",
        "plt.title('Top 20 diag_2 Frequencies')\n",
        "plt.xlabel('diag_2')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JMLnmQ_p1WZV"
      },
      "outputs": [],
      "source": [
        "# Bar chart for diag_3\n",
        "plt.figure(figsize=(12, 6))\n",
        "df['diag_3'].value_counts().nlargest(20).plot(kind='bar')\n",
        "plt.title('Top 20 diag_3 Frequencies')\n",
        "plt.xlabel('diag_3')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2DeatRf_CV1"
      },
      "source": [
        "## Multivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZljLHvPS_I0a"
      },
      "outputs": [],
      "source": [
        "# Correlation heatmaps for numerical_cols to spot multicollinearity.\n",
        "\n",
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Numerical Features')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN-5f0HAGelq"
      },
      "source": [
        "Analyze features like age, gender, or admission details, which might provide insights into risk factors for early versus late readmissions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq0Xya4OHBPn"
      },
      "outputs": [],
      "source": [
        "# Bar Plot or Count Plot: If age is categorical (like the bracketed format), a bar chart showing the count of patients in each age group helps reveal whether the dataset skews older or younger.\n",
        "\n",
        "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='age', data=df)\n",
        "plt.title('Count of Patients in Each Age Group')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6MjExvYI0jA"
      },
      "outputs": [],
      "source": [
        "# Apply chi-square tests (for categorical age brackets)\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(df['age'], df['readmitted'])\n",
        "\n",
        "# Perform the Chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(\"Expected frequencies:\")\n",
        "print(expected)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05  # Significance level\n",
        "\n",
        "if p < alpha:\n",
        "    print(\"There is a statistically significant association between age and readmission.\")\n",
        "else:\n",
        "    print(\"There is no statistically significant association between age and readmission.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "159BepuwFzvv"
      },
      "outputs": [],
      "source": [
        "# Function to convert an age bracket to its midpoint\n",
        "\n",
        "def convert_age_bracket_to_midpoint(age_bracket):\n",
        "    # Remove square brackets if they exist\n",
        "    age_bracket = age_bracket.strip('[]')\n",
        "    # Split the string into lower and upper bounds using the hyphen\n",
        "    parts = age_bracket.split('-')\n",
        "    # Check if we have two parts and try to compute the midpoint\n",
        "    if len(parts) == 2:\n",
        "        lower = parts[0]\n",
        "        upper = parts[1]\n",
        "\n",
        "        # Handle potential closing parenthesis in upper bound\n",
        "        if upper.endswith(')'):\n",
        "            upper = upper[:-1]  # Remove the ')'\n",
        "\n",
        "        try:\n",
        "            lower = float(lower)\n",
        "            upper = float(upper)\n",
        "            # Calculate midpoint for half-open interval: (lower + upper - 1)/2\n",
        "            # Since the upper bound is exclusive, we use upper-1 to make it inclusive.\n",
        "            midpoint = (lower + upper) / 2\n",
        "            return midpoint\n",
        "        except ValueError:\n",
        "            return None\n",
        "    return None\n",
        "# Apply the function to the 'age' column and create a new column 'age_midpoint'\n",
        "df['age_midpoint'] = df['age'].apply(convert_age_bracket_to_midpoint)\n",
        "\n",
        "# Display the original age and the computed midpoint for a few records\n",
        "print(df[['age', 'age_midpoint']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eA0URF1HGYx"
      },
      "outputs": [],
      "source": [
        "# Distribution Plot: If you transform the brackets into a numeric variable (e.g., midpoints), you can create a histogram or density plot to see the distribution of ages.\n",
        "\n",
        "# Create the distribution plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['age_midpoint'], kde=True, bins=10)  # Use kde for density plot\n",
        "plt.title('Distribution of Patient Ages')\n",
        "plt.xlabel('Age (Midpoint of Bracket)')\n",
        "plt.ylabel('Frequency/Density')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tveyf4VvHYmr"
      },
      "outputs": [],
      "source": [
        "# Readmission vs. Age: Perform a group-by operation (e.g., df.groupby('age')['readmission'].value_counts(normalize=True)) to see how readmission rates vary by age group. This might reveal that certain age brackets have higher or lower readmission probabilities.\n",
        "\n",
        "# Group by age and get normalized readmission counts\n",
        "readmission_by_age = df.groupby('age')['readmitted'].value_counts(normalize=True)\n",
        "readmission_by_age\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_vpAGhCHjC5"
      },
      "outputs": [],
      "source": [
        "# Other Features vs. Age: Explore how other variables (e.g., gender, diagnosis codes) distribute across age groups to spot any interesting correlations.\n",
        "\n",
        "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
        "\n",
        "# Group data by age and gender, then count readmissions\n",
        "readmission_by_age_gender = df.groupby(['age', 'gender'])['readmitted'].value_counts(normalize=True).unstack()\n",
        "\n",
        "# Plotting readmission rates by age and gender\n",
        "readmission_by_age_gender.plot(kind='bar', stacked=True, figsize=(15, 8))\n",
        "plt.title('Readmission Rates by Age and Gender')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Proportion of Readmissions')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Readmission Class')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCnEVtxkH61B"
      },
      "outputs": [],
      "source": [
        "# Group data by age and diagnosis code, then count readmissions\n",
        "# (Example using diag_1, repeat for diag_2 and diag_3)\n",
        "\n",
        "#The issue with the original plotting was that it tried to plot every combination of age, diag_1 and readmission status as a bar.\n",
        "#This resulted in an incomprehensible graph due to the sheer number of bars.\n",
        "# We can instead look at readmission rates for the top N diagnoses in each age group.\n",
        "\n",
        "\n",
        "def plot_readmissions_by_age_diagnosis(df, diagnosis_col, top_n=10):\n",
        "    for age_group in df['age'].unique():\n",
        "        # Filter data for the current age group\n",
        "        age_df = df[df['age'] == age_group]\n",
        "\n",
        "        # Get the top N diagnoses for this age group\n",
        "        top_diagnoses = age_df[diagnosis_col].value_counts().nlargest(top_n).index\n",
        "\n",
        "        # Filter the data to include only the top diagnoses\n",
        "        filtered_df = age_df[age_df[diagnosis_col].isin(top_diagnoses)]\n",
        "\n",
        "        # Group by diagnosis code and calculate readmission rates\n",
        "        readmission_rates = filtered_df.groupby(diagnosis_col)['readmitted'].value_counts(normalize=True).unstack()\n",
        "\n",
        "\n",
        "        # Plotting readmission rates\n",
        "        plt.figure(figsize=(12, 6))  # Adjust figure size as needed\n",
        "        readmission_rates.plot(kind='bar', stacked=True)\n",
        "        plt.title(f'Readmission Rates for Top {top_n} {diagnosis_col} in Age Group: {age_group}')\n",
        "        plt.xlabel(diagnosis_col)\n",
        "        plt.ylabel('Proportion of Readmissions')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.legend(title='Readmission Class')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Call the function for each diagnosis column\n",
        "plot_readmissions_by_age_diagnosis(df, 'diag_1')\n",
        "plot_readmissions_by_age_diagnosis(df, 'diag_2')\n",
        "plot_readmissions_by_age_diagnosis(df, 'diag_3')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljLrg8Sr_nIT"
      },
      "outputs": [],
      "source": [
        "# Aalyze features like age, gender, or admission details, which might provide insights into risk factors for early versus late readmissions.\n",
        "\n",
        "# Analyze features like age, gender, and admission details for readmission risk.\n",
        "\n",
        "# Assuming 'df' is your DataFrame (as defined in the previous code)\n",
        "\n",
        "\n",
        "# 2. Gender:\n",
        "# Compare readmission rates between genders\n",
        "gender_readmission = df.groupby('gender')['readmitted'].value_counts(normalize=True).unstack()\n",
        "print(gender_readmission)\n",
        "\n",
        "gender_readmission.plot(kind='bar', stacked=True)\n",
        "plt.title('Readmission Rates by Gender')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0h33vZSEQ39"
      },
      "outputs": [],
      "source": [
        "# 3. Admission Details:\n",
        "# Analyze admission type, admission source, and time in hospital for readmission correlation.\n",
        "\n",
        "# Admission Type\n",
        "admission_type_readmission = df.groupby('admission_type_id')['readmitted'].value_counts(normalize=True).unstack()\n",
        "print(admission_type_readmission)\n",
        "admission_type_readmission.plot(kind='bar', stacked=True)\n",
        "plt.title('Readmission Rates by Admission Type')\n",
        "plt.show()\n",
        "\n",
        "# Admission Source\n",
        "admission_source_readmission = df.groupby('admission_source_id')['readmitted'].value_counts(normalize=True).unstack()\n",
        "print(admission_source_readmission)\n",
        "admission_source_readmission.plot(kind='bar', stacked=True)\n",
        "plt.title('Readmission Rates by Admission Source')\n",
        "plt.show()\n",
        "\n",
        "# Time in Hospital\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.boxplot(x='readmitted',y='time_in_hospital',data=df)\n",
        "plt.title('Time in Hospital vs Readmission')\n",
        "plt.show()\n",
        "\n",
        "#Further analysis can include:\n",
        "# - Combining features (e.g., age and gender)\n",
        "# - Statistical tests (e.g., chi-squared test, t-test) to determine statistical significance\n",
        "# - More detailed visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRiadqu65_X7"
      },
      "source": [
        "# üìò 03. Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnvMcDWj5ZF8"
      },
      "outputs": [],
      "source": [
        "# Flag missing values\n",
        "for col in df.columns:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[f\"{col}_is_missing\"] = df[col].isnull()\n",
        "\n",
        "# Drop fully null columns\n",
        "df = df.dropna(axis=1, how='all')\n",
        "\n",
        "# Convert age ranges to numeric average\n",
        "df['age'] = df['age'].str.replace('[', '', regex=False).str.replace(')', '', regex=False)\n",
        "df['age'] = df['age'].str.split('-').apply(lambda x: (int(x[0]) + int(x[1])) / 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxxrXJgm59om"
      },
      "source": [
        "# üìò 04. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFd3qa645dSM"
      },
      "outputs": [],
      "source": [
        "# Simplify ICD-9 codes to numeric prefix\n",
        "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
        "    df[col] = df[col].astype(str).str.extract(r'(\\d+)', expand=False).astype(float)\n",
        "    df[col] = df[col].fillna(0)  # 0 = unknown/invalid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0WryDDX62pa"
      },
      "outputs": [],
      "source": [
        "# Encode categorical features\n",
        "categorical_cols = df.select_dtypes(include='object').columns.drop('readmitted')\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQGiQtlRLpxs"
      },
      "source": [
        "## Additional from Cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yybiYaddLeZV"
      },
      "outputs": [],
      "source": [
        "# Check if this is_missing_weight and is_missing_payer_code correlates with the readmission outcome. If the correlation or importance is high\n",
        "\n",
        "# Calculate the correlation between 'is_missing_weight', 'is_missing_payer_code', and 'readmitted'\n",
        "correlation_weight = df_copy['is_missing_weight'].corr(df_copy['readmitted'] != 'NO')\n",
        "correlation_payer = df_copy['is_missing_payer_code'].corr(df_copy['readmitted'] != 'NO')\n",
        "\n",
        "print(f\"Correlation between is_missing_weight and readmission: {correlation_weight}\")\n",
        "print(f\"Correlation between is_missing_payer_code and readmission: {correlation_payer}\")\n",
        "\n",
        "# Using RandomForestClassifier to assess feature importance\n",
        "X = df_copy[['is_missing_weight', 'is_missing_payer_code']]  # Features\n",
        "y = df_copy['readmitted'] != 'NO' # Target variable (readmitted or not)\n",
        "\n",
        "\n",
        "# Handle non-numeric data (if any) in the features. Assuming boolean values already are represented numerically.\n",
        "X = X.astype(int) # Convert boolean values to integers (0 or 1) for the classifier\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature, importance in zip(['is_missing_weight', 'is_missing_payer_code'], feature_importances):\n",
        "    print(f\"{feature}: {importance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBevETcn571o"
      },
      "source": [
        "# üìà 05. Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEGaEnzw5gc-"
      },
      "outputs": [],
      "source": [
        "# Target distribution\n",
        "sns.countplot(x='readmitted', data=df)\n",
        "plt.title(\"Readmission Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8eE1TjcEx-H"
      },
      "outputs": [],
      "source": [
        "# Calculate the distribution of the readmission classes\n",
        "readmission_counts = df['readmitted'].value_counts()\n",
        "print(\"Readmission Counts:\")\n",
        "print(readmission_counts)\n",
        "\n",
        "# Plot the distribution as a bar chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "readmission_counts.plot(kind='bar', color=['skyblue', 'salmon', 'lightgreen'])\n",
        "plt.title(\"Distribution of Readmission Classes\")\n",
        "plt.xlabel(\"Readmission Category\")\n",
        "plt.ylabel(\"Number of Cases\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG4_6iBl7JNP"
      },
      "outputs": [],
      "source": [
        "# Only include numeric columns for correlation\n",
        "numeric_df = df_encoded.select_dtypes(include=[np.number])\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(numeric_df.corr(), cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZWgREQ-56Eh"
      },
      "source": [
        "# üìò 06. Modeling Strategy and Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uSKd3mT5j8u"
      },
      "outputs": [],
      "source": [
        "X = df_encoded.drop('readmitted', axis=1)\n",
        "y = df['readmitted']\n",
        "\n",
        "# Maintain class balance\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=10000, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, stratify=y_train_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlaKZKVf53XI"
      },
      "source": [
        "# üìò 07. Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEXuObhh5nTQ"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validation results\n",
        "y_pred = model.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# üìä Feature importances\n",
        "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "importances.nlargest(10).plot(kind='barh')\n",
        "plt.title(\"Top 10 Feature Importances\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyEItIx5rEO"
      },
      "source": [
        "# üìò 08. Interpretation and Business Recommendations\n",
        "\n",
        "## Key Insights\n",
        "- Feature importance analysis shows top predictors: e.g. number of medications, time in hospital.\n",
        "- The model can identify high-risk readmissions, especially <30 days, which are the most costly.\n",
        "\n",
        "## Recommended Actions\n",
        "- Use predictions to flag high-risk patients for follow-up.\n",
        "- Allocate nurse case managers for <30 day risk patients.\n",
        "- Educate patients before discharge to reduce recurrence.\n",
        "\n",
        "## Cost Savings Potential\n",
        "If model reduces <30 day readmissions by even 5%, estimated savings = millions annually (based on per patient cost of ~$13k).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiQTjsMk2zee"
      },
      "source": [
        "# üìò 09. Conclusion and Next Steps\n",
        "\n",
        "## Summary\n",
        "- We built a predictive model for hospital readmission among diabetic patients.\n",
        "- Our model improved upon baseline accuracy (53.9%).\n",
        "- We identified key variables and actionable insights for healthcare providers.\n",
        "\n",
        "## Limitations\n",
        "- Many missing values\n",
        "- Diagnoses not granularly explored (ICD-9 clusters could be used)\n",
        "\n",
        "## Next Steps\n",
        "- Experiment with multiclass + binary model combo\n",
        "- Try advanced models (XGBoost, LightGBM)\n",
        "- Apply cost-sensitive learning or upsampling minority class\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
