{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ad7be6-0554-4b5e-9824-a801dcce0a30",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "# Cost-Sensitive Random Forest Model with Lower Cost Scenario\n",
    "This notebook implements a Random Forest model with a different cost structure:\n",
    "- Lower cost of missed readmission: $11,000 (instead of $15,000)\n",
    "- Much lower cost of prevention intervention: $2,800 (instead of $6,600 or $8,400)\n",
    "This represents a scenario where readmissions are less costly but interventions are\n",
    "significantly more affordable, potentially making them economically viable for more patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223435ad-2c61-4039-9718-63c8344a4573",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Import Libraries and Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469f2a38-3c44-4d67-9da6-6bc13f2a793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost-Sensitive Random Forest Model with Lower Cost Scenario\n",
      "================================================================================\n",
      "Cost parameters:\n",
      "- Readmission cost: $11000\n",
      "- Intervention cost: $4000\n",
      "- Net benefit per prevented readmission: $7000\n",
      "- Cost ratio (readmission:intervention): 2.8:1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, \n",
    "    roc_curve, auc\n",
    ")\n",
    "\n",
    "# Visualization settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')  # Updated style for newer matplotlib versions\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(100)\n",
    "\n",
    "# Cost Parameters\n",
    "READMISSION_COST = 11000  # Lower cost of a readmission in dollars\n",
    "INTERVENTION_COST = 4000  # Much lower cost of preventive intervention\n",
    "\n",
    "print(\"Cost-Sensitive Random Forest Model with Lower Cost Scenario\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Cost parameters:\")\n",
    "print(f\"- Readmission cost: ${READMISSION_COST}\")\n",
    "print(f\"- Intervention cost: ${INTERVENTION_COST}\")\n",
    "print(f\"- Net benefit per prevented readmission: ${READMISSION_COST - INTERVENTION_COST}\")\n",
    "print(f\"- Cost ratio (readmission:intervention): {READMISSION_COST/INTERVENTION_COST:.1f}:1\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d407ad1-522c-47ec-a0b9-e12346369455",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364e3839-50f8-4841-b564-12052d5f5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (101766, 50)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    df = pd.read_csv('diabetic_readmission_data.csv')\n",
    "    print(f\"Dataset dimensions: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found.\")\n",
    "    print(\"Please ensure 'diabetic_readmission_data.csv' is in the working directory.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a15e8f-8c10-4933-b740-aa45f3ebd56a",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "### Data Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39683de7-914f-4546-be70-ee56fe3574a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Data Preprocessing \n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Replace '?' with NaN\n",
    "df_processed = df.copy()\n",
    "df_processed = df_processed.replace('?', np.nan)\n",
    "df_processed = df_processed.replace('Unknown/Invalid', np.nan)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_drop = ['weight', 'payer_code', 'medical_specialty', 'examide', 'citoglipton']\n",
    "df_processed = df_processed.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Remove encounters with death outcomes\n",
    "death_discharge_ids = [11, 13, 14, 19, 20, 21]\n",
    "df_processed = df_processed[~df_processed['discharge_disposition_id'].isin(death_discharge_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a128bf-815d-4510-bdb0-f4a4337af867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Process diagnosis codes\n",
    "def categorize_diagnosis(code):\n",
    "    if pd.isna(code) or code == '':\n",
    "        return 'Other'\n",
    "    \n",
    "    code = str(code)\n",
    "    if code.startswith('V') or code.startswith('E'):\n",
    "        return 'Other'\n",
    "    \n",
    "    try:\n",
    "        code_num = float(code)\n",
    "        \n",
    "        if 390 <= code_num <= 459 or code_num == 785:\n",
    "            return 'Circulatory'\n",
    "        elif 460 <= code_num <= 519 or code_num == 786:\n",
    "            return 'Respiratory'\n",
    "        elif 520 <= code_num <= 579 or code_num == 787:\n",
    "            return 'Digestive'\n",
    "        elif code_num == 250:\n",
    "            return 'Diabetes'\n",
    "        elif 800 <= code_num <= 999:\n",
    "            return 'Injury'\n",
    "        elif 710 <= code_num <= 739:\n",
    "            return 'Musculoskeletal'\n",
    "        elif 580 <= code_num <= 629 or code_num == 788:\n",
    "            return 'Genitourinary'\n",
    "        elif 140 <= code_num <= 239:\n",
    "            return 'Neoplasms'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    except ValueError:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply categorization to diagnosis columns\n",
    "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    df_processed[f'{col}_category'] = df_processed[col].apply(categorize_diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ebfd70-012b-472a-a190-a9eff5680cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Process age\n",
    "def age_to_midpoint(age_bracket):\n",
    "    if pd.isna(age_bracket):\n",
    "        return np.nan\n",
    "    \n",
    "    numbers = re.findall(r'\\d+', age_bracket)\n",
    "    if len(numbers) == 2:\n",
    "        return (int(numbers[0]) + int(numbers[1])) / 2\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df_processed['age_midpoint'] = df_processed['age'].apply(age_to_midpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554abfc9-2b81-4721-ad9c-ce3861b45665",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "### Feature Engineering and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e294316e-88b0-429e-bfbf-24a92b0a64af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features...\n",
      "Filling NaN values in race with median...\n",
      "Filling NaN values in gender with median...\n",
      "Filling NaN values in max_glu_serum with median...\n",
      "Filling NaN values in A1Cresult with median...\n",
      "Filling NaN values in metformin with median...\n",
      "Filling NaN values in repaglinide with median...\n",
      "Filling NaN values in nateglinide with median...\n",
      "Filling NaN values in chlorpropamide with median...\n",
      "Filling NaN values in glimepiride with median...\n",
      "Filling NaN values in acetohexamide with median...\n",
      "Filling NaN values in glipizide with median...\n",
      "Filling NaN values in glyburide with median...\n",
      "Filling NaN values in tolbutamide with median...\n",
      "Filling NaN values in pioglitazone with median...\n",
      "Filling NaN values in rosiglitazone with median...\n",
      "Filling NaN values in acarbose with median...\n",
      "Filling NaN values in miglitol with median...\n",
      "Filling NaN values in troglitazone with median...\n",
      "Filling NaN values in tolazamide with median...\n",
      "Filling NaN values in insulin with median...\n",
      "Filling NaN values in glyburide-metformin with median...\n",
      "Filling NaN values in glipizide-metformin with median...\n",
      "Filling NaN values in glimepiride-pioglitazone with median...\n",
      "Filling NaN values in metformin-rosiglitazone with median...\n",
      "Filling NaN values in metformin-pioglitazone with median...\n",
      "Filling NaN values in change with median...\n",
      "Filling NaN values in diabetesMed with median...\n",
      "Filling NaN values in diag_1_category with median...\n",
      "Filling NaN values in diag_2_category with median...\n",
      "Filling NaN values in diag_3_category with median...\n",
      "Warning: Still have NaN values! Using more aggressive filling...\n",
      "All NaN values have been handled successfully.\n",
      "Number of features: 42\n",
      "\n",
      "Class distribution in the dataset:\n",
      "No Readmission (0): 52527 (52.87%)\n",
      "Readmission (1): 46816 (47.13%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = df_processed.copy()\n",
    "categorical_columns = [\n",
    "    'race', 'gender', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide',\n",
    "    'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide',\n",
    "    'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
    "    'miglitol', 'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin',\n",
    "    'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "    'metformin-pioglitazone', 'change', 'diabetesMed', 'diag_1_category',\n",
    "    'diag_2_category', 'diag_3_category'\n",
    "]\n",
    "\n",
    "# Ensure all features are numeric\n",
    "for col in df_encoded.columns:\n",
    "    # Skip the target and ID columns\n",
    "    if col in ['readmitted', 'encounter_id', 'patient_nbr', 'diag_1', 'diag_2', 'diag_3']:\n",
    "        continue\n",
    "    \n",
    "    # Try to convert to numeric\n",
    "    if df_encoded[col].dtype == 'object':\n",
    "        try:\n",
    "            df_encoded[col] = pd.to_numeric(df_encoded[col], errors='coerce')\n",
    "        except:\n",
    "            # For categorical columns, use label encoding\n",
    "            if col in categorical_columns:\n",
    "                le = LabelEncoder()\n",
    "                # Handle NaN values\n",
    "                df_encoded[col] = df_encoded[col].fillna('Missing')\n",
    "                df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "\n",
    "# Convert target variable to binary\n",
    "df_encoded['readmitted_binary'] = df_encoded['readmitted'].map({'<30': 1, '>30': 1, 'NO': 0})\n",
    "\n",
    "# Feature Selection\n",
    "print(\"Selecting features...\")\n",
    "\n",
    "# Select features\n",
    "available_features = []\n",
    "for feat in df_encoded.columns:\n",
    "    # Skip IDs, original target, and diagnosis codes\n",
    "    if feat in ['encounter_id', 'patient_nbr', 'readmitted', 'diag_1', 'diag_2', 'diag_3', 'age', 'readmitted_binary']:\n",
    "        continue\n",
    "    \n",
    "    # Only keep numeric columns\n",
    "    if pd.api.types.is_numeric_dtype(df_encoded[feat]):\n",
    "        available_features.append(feat)\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = df_encoded[available_features]\n",
    "y = df_encoded['readmitted_binary']\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().any():\n",
    "        print(f\"Filling NaN values in {col} with median...\")\n",
    "        X.loc[:, col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Double-check for any remaining NaN values\n",
    "if X.isnull().any().any():\n",
    "    print(\"Warning: Still have NaN values! Using more aggressive filling...\")\n",
    "    # If there are columns with all NaN, fill with 0\n",
    "    for col in X.columns:\n",
    "        if X[col].isnull().any():\n",
    "            X.loc[:, col] = X[col].fillna(0)\n",
    "\n",
    "# Final verification\n",
    "assert not X.isnull().any().any(), \"Error: Still have NaN values after filling\"\n",
    "print(\"All NaN values have been handled successfully.\")\n",
    "\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "\n",
    "# Display class distribution\n",
    "print(\"\\nClass distribution in the dataset:\")\n",
    "readmit_counts = y.value_counts()\n",
    "readmit_percent = y.value_counts(normalize=True) * 100\n",
    "print(f\"No Readmission (0): {readmit_counts[0]} ({readmit_percent[0]:.2f}%)\")\n",
    "print(f\"Readmission (1): {readmit_counts[1]} ({readmit_percent[1]:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644121f8-9340-42f1-91a1-c78528143b98",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "### Split Data and Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e0fa05-d744-490b-ab3f-355ce538e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set after SMOTE balancing:\n",
      "No Readmission (0): 42021 (50.0%)\n",
      "Readmission (1): 42021 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=100, stratify=y\n",
    ")\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=100)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nTraining set after SMOTE balancing:\")\n",
    "print(f\"No Readmission (0): {sum(y_train_balanced == 0)} (50.0%)\")\n",
    "print(f\"Readmission (1): {sum(y_train_balanced == 1)} (50.0%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e14fce-b881-4eaa-a78a-640766a5ae3a",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Cost Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4640a71f-41a8-47fc-8c08-50cbb90df378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def calculate_costs(y_true, y_pred, verbose=True):\n",
    "    \"\"\"\n",
    "    Calculate direct costs based on the confusion matrix.\n",
    "    \n",
    "    Assumptions:\n",
    "    - True Positives (TP): We intervene, cost = INTERVENTION_COST\n",
    "    - False Positives (FP): We intervene unnecessarily, cost = INTERVENTION_COST\n",
    "    - False Negatives (FN): We miss a readmission, cost = READMISSION_COST\n",
    "    - True Negatives (TN): No intervention, no readmission, cost = 0\n",
    "    \"\"\"\n",
    "    # Get confusion matrix values\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate costs for each category\n",
    "    cost_tp = tp * INTERVENTION_COST\n",
    "    cost_fp = fp * INTERVENTION_COST\n",
    "    cost_fn = fn * READMISSION_COST\n",
    "    cost_tn = 0  # No cost\n",
    "    \n",
    "    # Total cost\n",
    "    total_cost = cost_tp + cost_fp + cost_fn + cost_tn\n",
    "    \n",
    "    # Cost breakdown\n",
    "    if verbose:\n",
    "        print(f\"\\nCost Analysis:\")\n",
    "        print(f\"- TP (correct interventions): {tp} × ${INTERVENTION_COST} = ${cost_tp:,.2f}\")\n",
    "        print(f\"- FP (unnecessary interventions): {fp} × ${INTERVENTION_COST} = ${cost_fp:,.2f}\")\n",
    "        print(f\"- FN (missed readmissions): {fn} × ${READMISSION_COST} = ${cost_fn:,.2f}\")\n",
    "        print(f\"- TN (correct non-interventions): {tn} × $0 = $0.00\")\n",
    "        print(f\"- Total cost: ${total_cost:,.2f}\")\n",
    "    \n",
    "    # Calculate minimum possible cost (perfect prediction)\n",
    "    min_cost = sum(y_true) * INTERVENTION_COST\n",
    "    \n",
    "    # Calculate cost of doing nothing (all negatives)\n",
    "    do_nothing_cost = sum(y_true) * READMISSION_COST\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nBenchmarks:\")\n",
    "        print(f\"- Perfect prediction cost: ${min_cost:,.2f}\")\n",
    "        print(f\"- Cost of doing nothing: ${do_nothing_cost:,.2f}\")\n",
    "        \n",
    "        if total_cost < do_nothing_cost:\n",
    "            savings = do_nothing_cost - total_cost\n",
    "            print(f\"- Savings vs. doing nothing: ${savings:,.2f} ({savings/do_nothing_cost:.1%})\")\n",
    "        else:\n",
    "            loss = total_cost - do_nothing_cost\n",
    "            print(f\"- Loss vs. doing nothing: ${loss:,.2f} ({loss/do_nothing_cost:.1%})\")\n",
    "    \n",
    "    return {\n",
    "        'total_cost': total_cost,\n",
    "        'min_cost': min_cost,\n",
    "        'do_nothing_cost': do_nothing_cost,\n",
    "        'confusion_matrix': cm,\n",
    "        'cost_detail': {\n",
    "            'tp': cost_tp,\n",
    "            'fp': cost_fp,\n",
    "            'fn': cost_fn,\n",
    "            'tn': cost_tn\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c6ba1-2644-4402-b4e1-396091565964",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Baseline Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6cd3d2-d16f-4401-a120-e8a4ba724562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Baseline Random Forest Model (without cost sensitivity)\n",
      "================================================================================\n",
      "Test accuracy: 0.6040\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63     10506\n",
      "           1       0.58      0.58      0.58      9363\n",
      "\n",
      "    accuracy                           0.60     19869\n",
      "   macro avg       0.60      0.60      0.60     19869\n",
      "weighted avg       0.60      0.60      0.60     19869\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6572 3934]\n",
      " [3935 5428]]\n",
      "\n",
      "Cost Analysis:\n",
      "- TP (correct interventions): 5428 × $4000 = $21,712,000.00\n",
      "- FP (unnecessary interventions): 3934 × $4000 = $15,736,000.00\n",
      "- FN (missed readmissions): 3935 × $11000 = $43,285,000.00\n",
      "- TN (correct non-interventions): 6572 × $0 = $0.00\n",
      "- Total cost: $80,733,000.00\n",
      "\n",
      "Benchmarks:\n",
      "- Perfect prediction cost: $37,452,000.00\n",
      "- Cost of doing nothing: $102,993,000.00\n",
      "- Savings vs. doing nothing: $22,260,000.00 (21.6%)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Baseline Random Forest Model (without cost sensitivity)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create and train the model\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_baseline.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_baseline = rf_baseline.predict(X_test)\n",
    "y_proba_baseline = rf_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "print(f\"Test accuracy: {accuracy_baseline:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "print(cm_baseline)\n",
    "\n",
    "# Calculate costs for baseline model\n",
    "baseline_costs = calculate_costs(y_test, y_pred_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a55d1-9670-4644-bdbc-7ba27f5d42e0",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Threshold Optimization for Cost Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65abbd59-9283-4288-9b14-65d07a0e060c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Threshold Optimization for Cost Minimization\n",
      "================================================================================\n",
      "Finding optimal threshold based on economic costs...\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Threshold Optimization for Cost Minimization\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate costs for different thresholds\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "costs = []\n",
    "metrics = []\n",
    "\n",
    "print(\"Finding optimal threshold based on economic costs...\")\n",
    "for threshold in thresholds:\n",
    "    # Get predictions at this threshold\n",
    "    y_pred_threshold = (y_proba_baseline >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate costs\n",
    "    cost_data = calculate_costs(y_test, y_pred_threshold, verbose=False)\n",
    "    costs.append(cost_data['total_cost'])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cm = cost_data['confusion_matrix']\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    metrics.append({\n",
    "        'threshold': threshold,\n",
    "        'total_cost': cost_data['total_cost'],\n",
    "        'accuracy': accuracy,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tp': tp\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c24d9c4-0d1d-4d36-80fd-b989693c097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.3400\n",
      "Cost at optimal threshold: $76,471,000.00\n",
      "\n",
      "Confusion Matrix at Optimal Threshold:\n",
      "[[3210 7296]\n",
      " [1405 7958]]\n",
      "\n",
      "Classification Report at Optimal Threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.31      0.42     10506\n",
      "           1       0.52      0.85      0.65      9363\n",
      "\n",
      "    accuracy                           0.56     19869\n",
      "   macro avg       0.61      0.58      0.54     19869\n",
      "weighted avg       0.61      0.56      0.53     19869\n",
      "\n",
      "\n",
      "Cost Analysis:\n",
      "- TP (correct interventions): 7958 × $4000 = $31,832,000.00\n",
      "- FP (unnecessary interventions): 7296 × $4000 = $29,184,000.00\n",
      "- FN (missed readmissions): 1405 × $11000 = $15,455,000.00\n",
      "- TN (correct non-interventions): 3210 × $0 = $0.00\n",
      "- Total cost: $76,471,000.00\n",
      "\n",
      "Benchmarks:\n",
      "- Perfect prediction cost: $37,452,000.00\n",
      "- Cost of doing nothing: $102,993,000.00\n",
      "- Savings vs. doing nothing: $26,522,000.00 (25.8%)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Find the optimal threshold\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "optimal_idx = metrics_df['total_cost'].idxmin()  # Minimize total cost\n",
    "optimal_threshold = metrics_df.loc[optimal_idx, 'threshold']\n",
    "optimal_cost = metrics_df.loc[optimal_idx, 'total_cost']\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Cost at optimal threshold: ${optimal_cost:,.2f}\")\n",
    "\n",
    "# Apply optimal threshold\n",
    "y_pred_optimal = (y_proba_baseline >= optimal_threshold).astype(int)\n",
    "\n",
    "print(\"\\nConfusion Matrix at Optimal Threshold:\")\n",
    "cm_optimal = confusion_matrix(y_test, y_pred_optimal)\n",
    "print(cm_optimal)\n",
    "\n",
    "print(\"\\nClassification Report at Optimal Threshold:\")\n",
    "print(classification_report(y_test, y_pred_optimal))\n",
    "\n",
    "# Calculate detailed costs for optimal threshold\n",
    "optimal_costs = calculate_costs(y_test, y_pred_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4e878-32a9-47f0-b2d0-7ec2138d1900",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Cost-Weighted Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa3b95e-eae4-4101-adec-b6d6495528a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cost-Weighted Random Forest Model\n",
      "================================================================================\n",
      "Class weights based on cost ratio: {0: 1.0, 1: 2.75}\n",
      "\n",
      "Classification Report for Cost-Weighted Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63     10506\n",
      "           1       0.58      0.56      0.57      9363\n",
      "\n",
      "    accuracy                           0.60     19869\n",
      "   macro avg       0.60      0.60      0.60     19869\n",
      "weighted avg       0.60      0.60      0.60     19869\n",
      "\n",
      "\n",
      "Confusion Matrix for Cost-Weighted Model:\n",
      "[[6749 3757]\n",
      " [4140 5223]]\n",
      "\n",
      "Cost Analysis:\n",
      "- TP (correct interventions): 5223 × $4000 = $20,892,000.00\n",
      "- FP (unnecessary interventions): 3757 × $4000 = $15,028,000.00\n",
      "- FN (missed readmissions): 4140 × $11000 = $45,540,000.00\n",
      "- TN (correct non-interventions): 6749 × $0 = $0.00\n",
      "- Total cost: $81,460,000.00\n",
      "\n",
      "Benchmarks:\n",
      "- Perfect prediction cost: $37,452,000.00\n",
      "- Cost of doing nothing: $102,993,000.00\n",
      "- Savings vs. doing nothing: $21,533,000.00 (20.9%)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cost-Weighted Random Forest Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = {\n",
    "    0: 1.0,  # Weight for negative class\n",
    "    1: READMISSION_COST / INTERVENTION_COST  # Weight for positive class\n",
    "}\n",
    "\n",
    "print(f\"Class weights based on cost ratio: {class_weights}\")\n",
    "\n",
    "# Train a cost-weighted model\n",
    "rf_weighted = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    class_weight=class_weights,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_weighted.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_weighted = rf_weighted.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nClassification Report for Cost-Weighted Model:\")\n",
    "print(classification_report(y_test, y_pred_weighted))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Cost-Weighted Model:\")\n",
    "cm_weighted = confusion_matrix(y_test, y_pred_weighted)\n",
    "print(cm_weighted)\n",
    "\n",
    "# Calculate costs for weighted model\n",
    "weighted_costs = calculate_costs(y_test, y_pred_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64854e-4378-45ca-a240-e5acba8fcfaa",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9f6065-6c5c-45e1-b5be-672fa087f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating visualizations...\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\nCreating visualizations...\")\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_baseline)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'Random Forest (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# Optimal threshold point on ROC curve\n",
    "optimal_fpr_idx = np.argmin(np.abs(thresholds - optimal_threshold))\n",
    "optimal_fpr = metrics_df.loc[optimal_idx, 'fp'] / (metrics_df.loc[optimal_idx, 'fp'] + metrics_df.loc[optimal_idx, 'tn'])\n",
    "optimal_tpr = metrics_df.loc[optimal_idx, 'tp'] / (metrics_df.loc[optimal_idx, 'tp'] + metrics_df.loc[optimal_idx, 'fn'])\n",
    "plt.scatter(optimal_fpr, optimal_tpr, marker='o', color='red', s=100, \n",
    "            label=f'Optimal Threshold ({optimal_threshold:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve with Economically Optimal Threshold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.savefig('lower_cost_roc_curve.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3911b99b-ebab-4303-93ca-42b1c7dce9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Plot costs by threshold\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(thresholds, costs)\n",
    "plt.scatter(optimal_threshold, optimal_cost, marker='o', color='red', s=100, \n",
    "            label=f'Optimal Threshold ({optimal_threshold:.2f})')\n",
    "plt.xlabel('Classification Threshold')\n",
    "plt.ylabel('Total Cost ($)')\n",
    "plt.title('Total Cost by Classification Threshold')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('lower_cost_by_threshold.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6d0c011-467d-4e60-b770-4993c48e08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Cost comparison between all models\n",
    "models = ['Baseline RF', 'Optimal Threshold RF', 'Cost-Weighted RF']\n",
    "model_costs = [baseline_costs['total_cost'], optimal_costs['total_cost'], weighted_costs['total_cost']]\n",
    "baseline_cost = baseline_costs['do_nothing_cost']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(models, model_costs)\n",
    "plt.axhline(y=baseline_cost, color='r', linestyle='-', label='Do Nothing Cost')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Total Cost ($)')\n",
    "plt.title('Cost Comparison Between Models')\n",
    "plt.grid(True, axis='y')\n",
    "plt.legend()\n",
    "\n",
    "# Add values on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    savings = baseline_cost - height\n",
    "    savings_pct = (savings / baseline_cost) * 100\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 5000000,\n",
    "             f'${height:,.0f}\\n(-${savings:,.0f}, {savings_pct:.1f}%)',\n",
    "             ha='center', va='bottom', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lower_cost_model_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9489c6b4-0aa3-4822-aba1-c6b7b519a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Cost-threshold relation with intervention percentage\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Primary axis for cost\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(thresholds, metrics_df['total_cost'] / 1e6, 'b-', linewidth=2, label='Total Cost ($ millions)')\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('Cost ($ millions)')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "ax1.axvline(x=optimal_threshold, color='purple', linestyle='--', \n",
    "            label=f'Optimal Threshold = {optimal_threshold:.2f}')\n",
    "\n",
    "# Secondary axis for percentage of population\n",
    "ax2 = ax1.twinx()\n",
    "intervention_pcts = [(metrics_df.loc[i, 'tp'] + metrics_df.loc[i, 'fp']) / len(y_test) * 100 \n",
    "                       for i in range(len(metrics_df))]\n",
    "ax2.plot(thresholds, intervention_pcts, 'g-', linewidth=2, label='% of Population Receiving Intervention')\n",
    "ax2.set_ylabel('% of Population')\n",
    "ax2.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "# Combine legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "plt.title('Total Cost and Intervention Coverage by Threshold')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lower_cost_threshold_coverage.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c5c9d-64bc-4a2a-8efe-b6ebdd2a6844",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dc349f2-12c8-4698-b6d9-b2e00fc2760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Summary of Results with Lower Cost Scenario\n",
      "================================================================================\n",
      "               Model     Threshold Accuracy Sensitivity Specificity % Intervened  Total Cost ($)    Savings ($) Savings (%)\n",
      "         Baseline RF        0.5000    60.4%       58.0%       62.6%        47.1%  $80,733,000.00 $22,260,000.00       21.6%\n",
      "Optimal Threshold RF        0.3400    56.2%       85.0%       30.6%        76.8%  $76,471,000.00 $26,522,000.00       25.8%\n",
      "    Cost-Weighted RF Cost-weighted    60.3%       55.8%       64.2%        45.2%  $81,460,000.00 $21,533,000.00       20.9%\n",
      "          Do Nothing           N/A    52.9%        0.0%      100.0%         0.0% $102,993,000.00          $0.00        0.0%\n",
      "\n",
      "Saved visualizations:\n",
      "1. lower_cost_roc_curve.png - ROC curve with optimal threshold\n",
      "2. lower_cost_by_threshold.png - Cost vs threshold analysis\n",
      "3. lower_cost_model_comparison.png - Cost comparison between models\n",
      "4. lower_cost_threshold_coverage.png - Cost and intervention coverage by threshold\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Summary of Results with Lower Cost Scenario\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate cost vs. doing nothing for all models\n",
    "baseline_vs_nothing = baseline_costs['total_cost'] - baseline_costs['do_nothing_cost']\n",
    "optimal_vs_nothing = optimal_costs['total_cost'] - optimal_costs['do_nothing_cost']\n",
    "weighted_vs_nothing = weighted_costs['total_cost'] - weighted_costs['do_nothing_cost']\n",
    "\n",
    "# Calculate intervention percentages\n",
    "baseline_intervention_pct = (cm_baseline[0,1] + cm_baseline[1,1]) / len(y_test) * 100\n",
    "optimal_intervention_pct = (cm_optimal[0,1] + cm_optimal[1,1]) / len(y_test) * 100\n",
    "weighted_intervention_pct = (cm_weighted[0,1] + cm_weighted[1,1]) / len(y_test) * 100\n",
    "\n",
    "# Create summary dataframe\n",
    "summary = pd.DataFrame({\n",
    "    'Model': ['Baseline RF', 'Optimal Threshold RF', 'Cost-Weighted RF', 'Do Nothing'],\n",
    "    'Threshold': [0.5, optimal_threshold, 'Cost-weighted', 'N/A'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_baseline),\n",
    "        accuracy_score(y_test, y_pred_optimal),\n",
    "        accuracy_score(y_test, y_pred_weighted),\n",
    "        accuracy_score(y_test, np.zeros_like(y_test))  # All negative\n",
    "    ],\n",
    "    'Sensitivity': [\n",
    "        cm_baseline[1,1] / (cm_baseline[1,0] + cm_baseline[1,1]),\n",
    "        cm_optimal[1,1] / (cm_optimal[1,0] + cm_optimal[1,1]),\n",
    "        cm_weighted[1,1] / (cm_weighted[1,0] + cm_weighted[1,1]),\n",
    "        0.0  # Do nothing has 0 sensitivity\n",
    "    ],\n",
    "    'Specificity': [\n",
    "        cm_baseline[0,0] / (cm_baseline[0,0] + cm_baseline[0,1]),\n",
    "        cm_optimal[0,0] / (cm_optimal[0,0] + cm_optimal[0,1]),\n",
    "        cm_weighted[0,0] / (cm_weighted[0,0] + cm_weighted[0,1]),\n",
    "        1.0  # Do nothing has 100% specificity\n",
    "    ],\n",
    "    '% Intervened': [\n",
    "        baseline_intervention_pct,\n",
    "        optimal_intervention_pct,\n",
    "        weighted_intervention_pct,\n",
    "        0.0  # Do nothing: 0% intervention\n",
    "    ],\n",
    "    'Total Cost ($)': [\n",
    "        baseline_costs['total_cost'],\n",
    "        optimal_costs['total_cost'],\n",
    "        weighted_costs['total_cost'],\n",
    "        baseline_costs['do_nothing_cost']  # Cost of doing nothing\n",
    "    ],\n",
    "    'Savings ($)': [\n",
    "        -baseline_vs_nothing if baseline_vs_nothing < 0 else baseline_vs_nothing,\n",
    "        -optimal_vs_nothing if optimal_vs_nothing < 0 else optimal_vs_nothing,\n",
    "        -weighted_vs_nothing if weighted_vs_nothing < 0 else weighted_vs_nothing,\n",
    "        0\n",
    "    ],\n",
    "    'Savings (%)': [\n",
    "        ((-baseline_vs_nothing if baseline_vs_nothing < 0 else baseline_vs_nothing) / baseline_costs['do_nothing_cost']) * 100,\n",
    "        ((-optimal_vs_nothing if optimal_vs_nothing < 0 else optimal_vs_nothing) / baseline_costs['do_nothing_cost']) * 100,\n",
    "        ((-weighted_vs_nothing if weighted_vs_nothing < 0 else weighted_vs_nothing) / weighted_costs['do_nothing_cost']) * 100,\n",
    "        0\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Format for display\n",
    "summary['Accuracy'] = summary['Accuracy'].map('{:.1%}'.format)\n",
    "summary['Sensitivity'] = summary['Sensitivity'].map('{:.1%}'.format)\n",
    "summary['Specificity'] = summary['Specificity'].map('{:.1%}'.format)\n",
    "summary['% Intervened'] = summary['% Intervened'].map('{:.1f}%'.format)\n",
    "summary['Threshold'] = summary['Threshold'].apply(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x)\n",
    "summary['Total Cost ($)'] = summary['Total Cost ($)'].map('${:,.2f}'.format)\n",
    "summary['Savings ($)'] = summary['Savings ($)'].map('${:,.2f}'.format)\n",
    "summary['Savings (%)'] = summary['Savings (%)'].map('{:.1f}%'.format)\n",
    "\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\nSaved visualizations:\")\n",
    "print(\"1. lower_cost_roc_curve.png - ROC curve with optimal threshold\")\n",
    "print(\"2. lower_cost_by_threshold.png - Cost vs threshold analysis\")\n",
    "print(\"3. lower_cost_model_comparison.png - Cost comparison between models\")\n",
    "print(\"4. lower_cost_threshold_coverage.png - Cost and intervention coverage by threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c538b-0d53-46a5-9372-62a2a8db52bb",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "559e04ea-899d-4af0-8ec5-1e9ae2d33045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusion:\n",
      "With the new cost structure (readmission: $11,000, intervention: $4,000):\n",
      "1. The best model is the Optimal Threshold RF\n",
      "2. It provides savings of $26,522,000.00 (25.8% reduction)\n",
      "3. The optimal threshold is 0.3400\n",
      "4. With this threshold, we would intervene with 76.8% of patients\n",
      "5. The ROI on interventions is 43.5%\n",
      "6. The break-even intervention cost would be $9350.00\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "do_nothing_cost = baseline_costs['do_nothing_cost']\n",
    "best_model_idx = [baseline_costs['total_cost'], optimal_costs['total_cost'], weighted_costs['total_cost']].index(\n",
    "    min([baseline_costs['total_cost'], optimal_costs['total_cost'], weighted_costs['total_cost']])\n",
    ")\n",
    "best_model_name = ['Baseline RF', 'Optimal Threshold RF', 'Cost-Weighted RF'][best_model_idx]\n",
    "best_model_cost = [baseline_costs['total_cost'], optimal_costs['total_cost'], weighted_costs['total_cost']][best_model_idx]\n",
    "best_savings = do_nothing_cost - best_model_cost\n",
    "\n",
    "print(f\"With the new cost structure (readmission: ${READMISSION_COST:,}, intervention: ${INTERVENTION_COST:,}):\")\n",
    "print(f\"1. The best model is the {best_model_name}\")\n",
    "print(f\"2. It provides savings of ${best_savings:,.2f} ({best_savings/do_nothing_cost:.1%} reduction)\")\n",
    "\n",
    "if best_model_name == 'Optimal Threshold RF':\n",
    "    intervention_pct = optimal_intervention_pct\n",
    "    print(f\"3. The optimal threshold is {optimal_threshold:.4f}\")\n",
    "    print(f\"4. With this threshold, we would intervene with {intervention_pct:.1f}% of patients\")\n",
    "    \n",
    "    # Calculate return on investment\n",
    "    tp = cm_optimal[1,1]  # True positives\n",
    "    fp = cm_optimal[0,1]  # False positives\n",
    "    investment = (tp + fp) * INTERVENTION_COST\n",
    "    return_avoided = tp * READMISSION_COST\n",
    "    roi = (return_avoided - investment) / investment\n",
    "    print(f\"5. The ROI on interventions is {roi:.1%}\")\n",
    "    \n",
    "    # Calculate break-even intervention cost\n",
    "    sensitivity_value = float(summary['Sensitivity'][1].rstrip('%')) / 100\n",
    "    break_even_cost = READMISSION_COST * sensitivity_value\n",
    "    print(f\"6. The break-even intervention cost would be ${break_even_cost:.2f}\")\n",
    "elif best_model_name == 'Cost-Weighted RF':\n",
    "    print(f\"3. This model uses class weights of {class_weights}\")\n",
    "    intervention_pct = weighted_intervention_pct\n",
    "    print(f\"4. With this approach, we would intervene with {intervention_pct:.1f}% of patients\")\n",
    "else:\n",
    "    print(f\"3. With low intervention costs, even the standard threshold of 0.5 is economically beneficial\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
